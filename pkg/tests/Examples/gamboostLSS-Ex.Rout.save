
R version 3.1.0 (2014-04-10) -- "Spring Dance"
Copyright (C) 2014 The R Foundation for Statistical Computing
Platform: x86_64-pc-linux-gnu (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> pkgname <- "gamboostLSS"
> source(file.path(R.home("share"), "R", "examples-header.R"))
> options(warn = 1)
> base::assign(".ExTimings", "gamboostLSS-Ex.timings", pos = 'CheckExEnv')
> base::cat("name\tuser\tsystem\telapsed\n", file=base::get(".ExTimings", pos = 'CheckExEnv'))
> base::assign(".format_ptime",
+ function(x) {
+   if(!is.na(x[4L])) x[1L] <- x[1L] + x[4L]
+   if(!is.na(x[5L])) x[2L] <- x[2L] + x[5L]
+   options(OutDec = '.')
+   format(x[1L:3L], digits = 7L)
+ },
+ pos = 'CheckExEnv')
> 
> ### * </HEADER>
> library('gamboostLSS')
Loading required package: mboost
Loading required package: parallel
Loading required package: survival
Loading required package: splines
This is mboost 2.2-3. See ‘package?mboost’ and the NEWS file
for a complete list of changes.
Note: The default for the computation of the degrees of freedom has changed.
      For details see section ‘Global Options’ of ‘?bols’.

Attaching package: ‘gamboostLSS’

The following object is masked from ‘package:stats’:

    model.weights

> 
> base::assign(".oldSearch", base::search(), pos = 'CheckExEnv')
> cleanEx()
> nameEx("as.families")
> ### * as.families
> 
> flush(stderr()); flush(stdout())
> 
> base::assign(".ptime", proc.time(), pos = "CheckExEnv")
> ### Name: as.families
> ### Title: Include 'gamlss' families in the boosting framework of
> ###   'gamboostLSS'
> ### Aliases: as.families gamlss.Families gamlss1parMu gamlss2parMu
> ###   gamlss2parSigma gamlss3parMu gamlss3parSigma gamlss3parNu
> ###   gamlss4parMu gamlss4parSigma gamlss4parNu gamlss4parTau
> ### Keywords: models distributions
> 
> ### ** Examples
> 
> ## simulate small example
> set.seed(123)
> x <- runif(1000)
> 
> y <- rnorm(mean = 2 + 3 * x,        # effect on mu
+            sd   = exp( 1 - 1 * x ), # effect on sigma
+            n    = 1000)
> 
> ## boosting
> glmss <- glmboostLSS(y ~ x, families = as.families("NO"))
> ## the same:
> glmss <- glmboostLSS(y ~ x, families = as.families(NO))
> glmss <- glmboostLSS(y ~ x, families = as.families(NO()))
> 
> coef(glmss, off2int = TRUE)
$mu
(Intercept)           x 
   2.114767    2.824394 

$sigma
(Intercept)           x 
   1.031368   -1.062068 

> 
> ## compare to gamlss
> library(gamlss)
Loading required package: gamlss.data
Loading required package: nlme
 **********   GAMLSS Version 4.3-0  ********** 
For more on GAMLSS look at http://www.gamlss.org/
Type gamlssNews() to see new features/changes/bug fixes.


Attaching package: ‘gamlss’

The following object is masked from ‘package:survival’:

    ridge

> glmss2 <- gamlss(y ~ x, sigma.formula = ~x, family = "NO")
GAMLSS-RS iteration 1: Global Deviance = 3844.26 
GAMLSS-RS iteration 2: Global Deviance = 3844.149 
GAMLSS-RS iteration 3: Global Deviance = 3844.149 
> coef(glmss2)
(Intercept)           x 
   2.110191    2.845264 
> glmss2$sigma.coef
(Intercept)           x 
   1.031275   -1.062060 
> 
> 
> 
> 
> base::assign(".dptime", (proc.time() - get(".ptime", pos = "CheckExEnv")), pos = "CheckExEnv")
> base::cat("as.families", base::get(".format_ptime", pos = 'CheckExEnv')(get(".dptime", pos = "CheckExEnv")), "\n", file=base::get(".ExTimings", pos = 'CheckExEnv'), append=TRUE, sep="\t")
> cleanEx()

detaching ‘package:gamlss’, ‘package:nlme’, ‘package:gamlss.data’,
  ‘package:gamlss.dist’, ‘package:MASS’

> nameEx("cvrisk")
> ### * cvrisk
> 
> flush(stderr()); flush(stdout())
> 
> base::assign(".ptime", proc.time(), pos = "CheckExEnv")
> ### Name: cvrisk.mboostLSS
> ### Title: Cross-Validation
> ### Aliases: cvrisk cvrisk.mboostLSS make.grid plot.cvriskLSS
> ### Keywords: models regression
> 
> ### ** Examples
> 
> ## Data generating process:
> set.seed(1907)
> x1 <- rnorm(1000)
> x2 <- rnorm(1000)
> x3 <- rnorm(1000)
> x4 <- rnorm(1000)
> x5 <- rnorm(1000)
> x6 <- rnorm(1000)
> mu    <- exp(1.5 +1 * x1 +0.5 * x2 -0.5 * x3 -1 * x4)
> sigma <- exp(-0.4 * x3 -0.2 * x4 +0.2 * x5 +0.4 * x6)
> y <- numeric(1000)
> for( i in 1:1000)
+     y[i] <- rnbinom(1, size = sigma[i], mu = mu[i])
> dat <- data.frame(x1, x2, x3, x4, x5, x6, y)
> 
> ## linear model with y ~ . for both components: 100 boosting iterations
> model <- glmboostLSS(y ~ ., families = NBinomialLSS(), data = dat,
+                      control = boost_control(mstop = 100),
+                      center = TRUE)
> 
> ## set up a grid
> grid <-  make.grid(mstop(model), length.out = 5, dense_mu_grid = FALSE)
> plot(grid)
> ## a tiny toy example (5-fold bootsrap with maximum stopping value 100)
> ##   (to run it on multiple cores of a Linux or Mac OS computer remove
> ##    set papply = mclapply (default) and set mc.nodes to the
> ##    appropriate number of nodes)
> cvr <- cvrisk(model, folds = cv(model.weights(model), B = 5),
+               papply = lapply, grid = grid)
Starting cross-validation...
[fold]	[current mstop]
 [1]	[1,1]
 [1]	[3,1]
 [1]	[10,1]
 [1]	[32,1]
 [1]	[100,1]
 [1]	[1,3]
 [1]	[3,3]
 [1]	[10,3]
 [1]	[32,3]
 [1]	[100,3]
 [1]	[1,10]
 [1]	[3,10]
 [1]	[10,10]
 [1]	[32,10]
 [1]	[100,10]
 [1]	[1,32]
 [1]	[3,32]
 [1]	[10,32]
 [1]	[32,32]
 [1]	[100,32]
 [1]	[1,100]
 [1]	[3,100]
 [1]	[10,100]
 [1]	[32,100]
 [1]	[100,100]
 [2]	[1,1]
 [2]	[3,1]
 [2]	[10,1]
 [2]	[32,1]
 [2]	[100,1]
 [2]	[1,3]
 [2]	[3,3]
 [2]	[10,3]
 [2]	[32,3]
 [2]	[100,3]
 [2]	[1,10]
 [2]	[3,10]
 [2]	[10,10]
 [2]	[32,10]
 [2]	[100,10]
 [2]	[1,32]
 [2]	[3,32]
 [2]	[10,32]
 [2]	[32,32]
 [2]	[100,32]
 [2]	[1,100]
 [2]	[3,100]
 [2]	[10,100]
 [2]	[32,100]
 [2]	[100,100]
 [3]	[1,1]
 [3]	[3,1]
 [3]	[10,1]
 [3]	[32,1]
 [3]	[100,1]
 [3]	[1,3]
 [3]	[3,3]
 [3]	[10,3]
 [3]	[32,3]
 [3]	[100,3]
 [3]	[1,10]
 [3]	[3,10]
 [3]	[10,10]
 [3]	[32,10]
 [3]	[100,10]
 [3]	[1,32]
 [3]	[3,32]
 [3]	[10,32]
 [3]	[32,32]
 [3]	[100,32]
 [3]	[1,100]
 [3]	[3,100]
 [3]	[10,100]
 [3]	[32,100]
 [3]	[100,100]
 [4]	[1,1]
 [4]	[3,1]
 [4]	[10,1]
 [4]	[32,1]
 [4]	[100,1]
 [4]	[1,3]
 [4]	[3,3]
 [4]	[10,3]
 [4]	[32,3]
 [4]	[100,3]
 [4]	[1,10]
 [4]	[3,10]
 [4]	[10,10]
 [4]	[32,10]
 [4]	[100,10]
 [4]	[1,32]
 [4]	[3,32]
 [4]	[10,32]
 [4]	[32,32]
 [4]	[100,32]
 [4]	[1,100]
 [4]	[3,100]
 [4]	[10,100]
 [4]	[32,100]
 [4]	[100,100]
 [5]	[1,1]
 [5]	[3,1]
 [5]	[10,1]
 [5]	[32,1]
 [5]	[100,1]
 [5]	[1,3]
 [5]	[3,3]
 [5]	[10,3]
 [5]	[32,3]
 [5]	[100,3]
 [5]	[1,10]
 [5]	[3,10]
 [5]	[10,10]
 [5]	[32,10]
 [5]	[100,10]
 [5]	[1,32]
 [5]	[3,32]
 [5]	[10,32]
 [5]	[32,32]
 [5]	[100,32]
 [5]	[1,100]
 [5]	[3,100]
 [5]	[10,100]
 [5]	[32,100]
 [5]	[100,100]
> cvr

	 Cross-validated risk
	 glmboostLSS(formula = y ~ ., data = dat, families = NBinomialLSS(),      control = boost_control(mstop = 100), center = TRUE) 

     1,1      3,1     10,1     32,1    100,1      1,3      3,3     10,3 
3.302710 3.289003 3.254355 3.201048 3.132957 3.299061 3.285124 3.249949 
    32,3    100,3     1,10     3,10    10,10    32,10   100,10     1,32 
3.195998 3.128614 3.292346 3.277996 3.240225 3.182837 3.117276 3.289440 
    3,32    10,32    32,32   100,32    1,100    3,100   10,100   32,100 
3.273384 3.228145 3.151754 3.088634 3.290803 3.272903 3.222363 3.120687 
 100,100 
3.020682 

	 Optimal number of boosting iterations: 100 100 
> 
> ## plot the results
> par(mfrow = c(1, 2))
> plot(cvr)
> plot(cvr, type = "lines")
> 
> ## extract optimal mstop (here: grid to small)
> mstop(cvr)
   mu sigma 
  100   100 
> 
> ## a more realistic example
> ## Not run: 
> ##D ## (automatically) as this really (!) takes a while
> ##D   ## set up a grid with maximum 400 for both components
> ##D   grid <- make.grid(c(mu = 400, sigma = 400), dense_mu_grid = FALSE)
> ##D   plot(grid)
> ##D   cvr <- cvrisk(model, grid = grid)
> ##D   mstop(cvr)
> ##D   ## reset model to mstop values:
> ##D   model[mstop(cvr)]
> ## End(Not run)
> ## Other grids:
> plot(make.grid(mstop(model), length.out = 3, dense_mu_grid = FALSE))
> plot(make.grid(c(mu = 400, sigma = 400), log = FALSE, dense_mu_grid = FALSE))
> plot(make.grid(c(mu = 400, sigma = 400), length.out = 4,
+                min = 100, log = FALSE, dense_mu_grid = FALSE))
> 
> 
> ### Now use dense mu grids
> 
> # standard grid
> plot(make.grid(c(mu = 100, sigma = 100), dense = FALSE),
+      pch = 20, col = "red")
> # dense grid for all mstop_mu values greater than mstop_sigma
> grid <- make.grid(c(mu = 100, sigma = 100))
> points(grid, pch = 20, cex = 0.2)
> abline(0,1)
> 
> # now with three parameters
> grid <- make.grid(c(mu = 100, sigma = 100, df = 30),
+                   length.out = c(5, 5, 2), dense = FALSE)
> densegrid <- make.grid(c(mu = 100, sigma = 100, df = 30),
+                        length.out = c(5, 5, 2))
> par(mfrow = c(1,2))
> # first for df = 1
> plot(grid[grid$df == 1, 1:2], main = "df = 1", pch = 20, col = "red")
> abline(0,1)
> abline(v = 1)
> # now expand grid for all mu values greater the corresponding sigma
> # value (i.e. below the bisecting line) and above df (i.e. 1)
> points(densegrid[densegrid$df == 1, 1:2], pch = 20, cex = 0.2)
> 
> # now for df = 30
> plot(grid[grid$df == 30, 1:2], main = "df = 30", pch = 20, col = "red")
> abline(0,1)
> abline(v = 30)
> # now expand grid for all mu values greater the corresponding sigma
> # value (i.e. below the bisecting line) and above df (i.e. 30)
> points(densegrid[densegrid$df == 30, 1:2], pch = 20, cex = 0.2)
> 
> 
> 
> base::assign(".dptime", (proc.time() - get(".ptime", pos = "CheckExEnv")), pos = "CheckExEnv")
> base::cat("cvrisk", base::get(".format_ptime", pos = 'CheckExEnv')(get(".dptime", pos = "CheckExEnv")), "\n", file=base::get(".ExTimings", pos = 'CheckExEnv'), append=TRUE, sep="\t")
> graphics::par(get("par.postscript", pos = 'CheckExEnv'))
> cleanEx()
> nameEx("families")
> ### * families
> 
> flush(stderr()); flush(stdout())
> 
> base::assign(".ptime", proc.time(), pos = "CheckExEnv")
> ### Name: Families
> ### Title: Families for GAMLSS models
> ### Aliases: Families families GaussianLSS GaussianMu GaussianSigma
> ###   GammaLSS GammaMu GammaSigma BetaLSS BetaMu BetaPhi NBinomialLSS
> ###   NBinomialMu NBinomialSigma StudentTLSS StudentTMu StudentTSigma
> ###   StudentTDf LogNormalLSS LogNormalMu LogNormalSigma WeibullLSS
> ###   WeibullMu WeibullSigma LogLogLSS LogLogMu LogLogSigma LogLogLSS
> ###   LogLogMu LogLogSigma ZIPoLSS ZINBLSS
> ### Keywords: models distributions
> 
> ### ** Examples
> 
> ## Example to define a new distribution:
> ## Students t-distribution with two parameters, df and mu:
> 
> ## sub-Family for mu
> ## -> generate object of the class family from the package mboost
> newStudentTMu  <- function(mu, df){
+ 
+     # loss is negative log-Likelihood, f is the parameter to be fitted with
+     # id link -> f = mu
+     loss <- function(df,  y, f) {
+         -1 * (lgamma((df + 1)/2)  - lgamma(1/2) -
+               lgamma(df/2) - 0.5 * log(df) -
+               (df + 1)/2 * log(1 + (y - f)^2/(df )))
+     }
+     # risk is sum of loss
+     risk <- function(y, f, w = 1) {
+         sum(w * loss(y = y, f = f, df = df))
+     }
+     # ngradient is the negative derivate w.r.t. mu
+     ngradient <- function(y, f, w = 1) {
+         (df + 1) * (y - f)/(df  + (y - f)^2)
+     }
+ 
+     # use the Family constructor of mboost
+     Family(ngradient = ngradient, risk = risk, loss = loss,
+            response = function(f) f,
+            name = "new Student's t-distribution: mu (id link)")
+ }
> 
> ## sub-Family for df
> newStudentTDf <- function(mu, df){
+ 
+     # loss is negative log-Likelihood, f is the parameter to be fitted with
+     # log-link: exp(f) = df
+     loss <- function( mu, y, f) {
+         -1 * (lgamma((exp(f) + 1)/2)  - lgamma(1/2) -
+               lgamma(exp(f)/2) - 0.5 * f -
+               (exp(f) + 1)/2 * log(1 + (y - mu)^2/(exp(f) )))
+     }
+     # risk is sum of loss
+     risk <- function(y, f, w = 1) {
+         sum(w * loss(y = y, f = f,  mu = mu))
+     }
+     # ngradient is the negative derivate w.r.t. df
+     ngradient <- function(y, f, w = 1) {
+         exp(f)/2 * (digamma((exp(f) + 1)/2) - digamma(exp(f)/2)) -
+             0.5 - (exp(f)/2 * log(1 + (y - mu)^2 / (exp(f) )) -
+                    (y - mu)^2 / (1 + (y - mu)^2 / exp(f)) * (exp(-f) + 1)/2)
+     }
+     # use the Family constructor of mboost
+     Family(ngradient = ngradient, risk = risk, loss = loss,
+            response = function(f) exp(f),
+            name = "Student's t-distribution: df (log link)")
+ }
> 
> ## families object for new distribution
> newStudentT <- Families(mu= newStudentTMu(mu=mu, df=df),
+                         df=newStudentTDf(mu=mu, df=df))
> 
> 
> ### usage of the new Student's t distribution:
> library(gamlss)   ## required for rTF
Loading required package: gamlss.data
Loading required package: gamlss.dist
Loading required package: MASS

Attaching package: ‘gamlss.dist’

The following object is masked from ‘package:mboost’:

    Family

Loading required package: nlme
 **********   GAMLSS Version 4.3-0  ********** 
For more on GAMLSS look at http://www.gamlss.org/
Type gamlssNews() to see new features/changes/bug fixes.


Attaching package: ‘gamlss’

The following object is masked from ‘package:survival’:

    ridge

> set.seed(1907)
> n <- 5000
> x1  <- runif(n)
> x2 <- runif(n)
> mu <- 2 -1*x1 - 3*x2
> df <- exp(1 + 0.5*x1 )
> y <- rTF(n = n, mu = mu, nu = df)
> 
> ## model fitting
> model <- glmboostLSS(y ~ x1 + x2, families = newStudentT,
+                      control = boost_control(mstop = 100),
+                      center = TRUE)
> ## shrinked effect estimates
> coef(model, off2int = TRUE)
$mu
(Intercept)          x1          x2 
  2.0013497  -0.9745979  -2.9987269 

$df
(Intercept)          x1 
  1.0798780   0.1213042 

> 
> ## compare to pre-defined three parametric t-distribution:
> model2 <- glmboostLSS(y ~ x1 + x2, families = StudentTLSS(),
+                       control = boost_control(mstop = 100),
+                       center = TRUE)
> coef(model2, off2int = TRUE)
$mu
(Intercept)          x1          x2 
  1.9900788  -0.9658828  -2.9889112 

$sigma
(Intercept)          x1          x2 
 0.01314517 -0.02731268  0.03867761 

$df
(Intercept)          x1 
  1.3213044   0.1913091 

> 
> ## with effect on sigma:
> sigma <- 3+ 1*x2
> y <- rTF(n = n, mu = mu, nu = df, sigma=sigma)
> model3 <- glmboostLSS(y ~ x1 + x2, families = StudentTLSS(),
+                       control = boost_control(mstop = 100),
+                       center = TRUE)
> coef(model3, off2int = TRUE)
$mu
(Intercept)          x2 
  0.5625243  -1.1556618 

$sigma
(Intercept)          x1          x2 
 1.17619100 -0.09742086  0.32657481 

$df
(Intercept)          x1          x2 
 1.14269183  0.33422503 -0.02387359 

> 
> 
> 
> 
> base::assign(".dptime", (proc.time() - get(".ptime", pos = "CheckExEnv")), pos = "CheckExEnv")
> base::cat("families", base::get(".format_ptime", pos = 'CheckExEnv')(get(".dptime", pos = "CheckExEnv")), "\n", file=base::get(".ExTimings", pos = 'CheckExEnv'), append=TRUE, sep="\t")
> cleanEx()

detaching ‘package:gamlss’, ‘package:nlme’, ‘package:gamlss.dist’,
  ‘package:MASS’, ‘package:gamlss.data’

> nameEx("gamboostLSS-package")
> ### * gamboostLSS-package
> 
> flush(stderr()); flush(stdout())
> 
> base::assign(".ptime", proc.time(), pos = "CheckExEnv")
> ### Name: gamboostLSS-package
> ### Title: Boosting algorithms for GAMLSS
> ### Aliases: gamboostLSS-package
> ### Keywords: package
> 
> ### ** Examples
> 
> # Generate covariates
> x1 <- runif(100)
> x2 <- runif(100)
> eta_mu <-     2 - 2*x1
> eta_sigma <-  -1  + 2*x2
> 
> # Generate response: Negative Binomial Distribution
> y <- numeric(100)
> for( i in 1:100)  y[i] <- rnbinom(1, size=exp(eta_sigma[i]), mu=exp(eta_mu[i]))
> 
> # Model fitting, 300 boosting steps, same formula for both distribution parameters
> mod1 <- glmboostLSS( y ~ x1 + x2, families=NBinomialLSS(),
+         control=boost_control(mstop=300), center = TRUE)
> 
> # Shrinked effect estimates
> coef(mod1, off2int=TRUE)
$mu
(Intercept)          x1          x2 
  2.3629274  -1.7170135  -0.7735303 

$sigma
(Intercept)          x1          x2 
 -0.3578293  -0.7798073   1.8236518 

> 
> # Empirical risk with respect to mu
> plot(risk(mod1)$mu)
> 
> # Empirical risk with respect to sigma
> plot(risk(mod1)$sigma)
> 
> 
> 
> base::assign(".dptime", (proc.time() - get(".ptime", pos = "CheckExEnv")), pos = "CheckExEnv")
> base::cat("gamboostLSS-package", base::get(".format_ptime", pos = 'CheckExEnv')(get(".dptime", pos = "CheckExEnv")), "\n", file=base::get(".ExTimings", pos = 'CheckExEnv'), append=TRUE, sep="\t")
> cleanEx()
> nameEx("india")
> ### * india
> 
> flush(stderr()); flush(stdout())
> 
> base::assign(".ptime", proc.time(), pos = "CheckExEnv")
> ### Name: india
> ### Title: Malnutrition of Children in India (DHS, 1998-99)
> ### Aliases: india india.bnd
> ### Keywords: datasets
> 
> ### ** Examples
> 
> if (require("BayesX")) {
+   ## plot distribution of stunting in India
+   drawmap(india, map = india.bnd, regionvar = "mcdist", plotvar = "stunting")
+ }
Loading required package: BayesX
Loading required package: shapefiles
Loading required package: foreign

Attaching package: ‘shapefiles’

The following objects are masked from ‘package:foreign’:

    read.dbf, write.dbf

Note: Function plotsurf depends on akima which has
 a restricted licence that explicitly forbids commercial use.
 akima is therefore disabled by default and may be enabled by
 akimaPermit(). Calling this function includes your agreement to
 akima`s licence restrictions.
> 
> 
> 
> base::assign(".dptime", (proc.time() - get(".ptime", pos = "CheckExEnv")), pos = "CheckExEnv")
> base::cat("india", base::get(".format_ptime", pos = 'CheckExEnv')(get(".dptime", pos = "CheckExEnv")), "\n", file=base::get(".ExTimings", pos = 'CheckExEnv'), append=TRUE, sep="\t")
> cleanEx()

detaching ‘package:BayesX’, ‘package:shapefiles’, ‘package:foreign’

> nameEx("mboostLSS")
> ### * mboostLSS
> 
> flush(stderr()); flush(stdout())
> 
> base::assign(".ptime", proc.time(), pos = "CheckExEnv")
> ### Name: mboostLSS
> ### Title: Fitting GAMLSS by Boosting
> ### Aliases: mboostLSS blackboostLSS glmboostLSS gamboostLSS mboostLSS_fit
> ###   options gamboostLSS_stab_ngrad stab_ngrad stabilize_ngrad
> ###   stabilize_ngradient
> ### Keywords: models nonlinear fitting
> 
> ### ** Examples
> 
> 
> ### Data generating process:
> set.seed(1907)
> x1 <- rnorm(1000)
> x2 <- rnorm(1000)
> x3 <- rnorm(1000)
> x4 <- rnorm(1000)
> x5 <- rnorm(1000)
> x6 <- rnorm(1000)
> mu    <- exp(1.5 +1 * x1 +0.5 * x2 -0.5 * x3 -1 * x4)
> sigma <- exp(-0.4 * x3 -0.2 * x4 +0.2 * x5 +0.4 * x6)
> y <- numeric(1000)
> for( i in 1:1000)
+     y[i] <- rnbinom(1, size = sigma[i], mu = mu[i])
> dat <- data.frame(x1, x2, x3, x4, x5, x6, y)
> 
> ### linear model with y ~ . for both components: 400 boosting iterations
> model <- glmboostLSS(y ~ ., families = NBinomialLSS(), data = dat,
+                      control = boost_control(mstop = 400),
+                      center = TRUE)
> coef(model, off2int = TRUE)
$mu
(Intercept)          x1          x2          x3          x4 
  1.6393421   0.9521780   0.4673261  -0.4553980  -0.8812656 

$sigma
(Intercept)          x1          x2          x3          x4          x5 
-0.21020051  0.18090759  0.03140974 -0.36216484 -0.27645489  0.13696242 
         x6 
 0.32951815 

> 
> 
> ### estimate model with different formulas for mu and sigma:
> names(NBinomialLSS())      # names of the family
[1] "mu"    "sigma"
> 
> # Note: Multiple formulas must be specified via a _named list_
> #       where the names correspond to the names of the distribution parameters
> #       in the family (see above)
> model2 <- glmboostLSS(formula = list(mu = y ~ x1 + x2 + x3 + x4,
+                                     sigma = y ~ x3 + x4 + x5 + x6),
+                      families = NBinomialLSS(), data = dat,
+                      control = boost_control(mstop = 400, trace = TRUE),
+                      center = TRUE)
[   1] ...................................... -- risk: 3102.966 
[  41] ...................................... -- risk: 3026.774 
[  81] ...................................... -- risk: 2963.095 
[ 121] ...................................... -- risk: 2901.378 
[ 161] ...................................... -- risk: 2841.725 
[ 201] ...................................... -- risk: 2788.547 
[ 241] ...................................... -- risk: 2746.665 
[ 281] ...................................... -- risk: 2717.919 
[ 321] ...................................... -- risk: 2700.384 
[ 361] ......................................
Final risk: 2690.598 
> coef(model2, off2int = TRUE)
$mu
(Intercept)          x1          x2          x3          x4 
  1.6068970   0.9754679   0.4773532  -0.4662399  -0.8897124 

$sigma
(Intercept)          x3          x4          x5          x6 
 -0.1230354  -0.3630657  -0.2697535   0.1403489   0.3301615 

> 
> 
> 
> ### Offset needs to be specified via the arguments of families object:
> model <- glmboostLSS(y ~ ., data = dat,
+                      families = NBinomialLSS(mu = mean(mu),
+                                              sigma = mean(sigma)),
+                      control = boost_control(mstop = 10),
+                      center = TRUE)
> # Note: mu-offset = log(mean(mu)) and sigma-offset = log(mean(sigma))
> #       as we use a log-link in both families
> coef(model)
$mu
(Intercept)          x1          x4 
-0.00644371  0.32790393 -0.22505852 
attr(,"offset")
[1] 2.843104

$sigma
(Intercept) 
 -0.6069266 
attr(,"offset")
[1] 0.1828927

> log(mean(mu))
[1] 2.843104
> log(mean(sigma))
[1] 0.1828927
> 
> ## Not run: 
> ##D ## (only as is takes some time)
> ##D ### use different mstop values for the two distribution parameters
> ##D ### (two-dimensional early stopping)
> ##D ### the number of iterations is passed to boost_control via a named list
> ##D model3 <- glmboostLSS(formula = list(mu = y ~ x1 + x2 + x3 + x4,
> ##D                                     sigma = y ~ x3 + x4 + x5 + x6),
> ##D                      families = NBinomialLSS(), data = dat,
> ##D                      control = boost_control(mstop = list(mu = 400,
> ##D                                                           sigma = 300),
> ##D                                              trace  = TRUE),
> ##D                      center = TRUE)
> ##D coef(model3, off2int = TRUE)
> ## End(Not run)
> ### Alternatively we can subset model2:
> # here it is assumed that the first element in the vector corresponds to
> # the first distribution parameter of model2 etc.
> model2[c(400, 300)]
Model first reduced to mstop = 300.
Now continue ...
[ 301] ...................................... -- risk: 2714.448 
[ 341] ...................................... -- risk: 2706.16 
[ 381] ..................
Final risk: 2703.712 

	 LSS Models fitted via Model-based Boosting

Call:
glmboostLSS(formula = list(mu = y ~ x1 + x2 + x3 + x4, sigma = y ~     x3 + x4 + x5 + x6), data = dat, families = NBinomialLSS(),     control = boost_control(mstop = 400, trace = TRUE), center = TRUE)

Number of boosting iterations: mstop = 400 300 
Step size:  0.1 

Families:

	 Negative Negative-Binomial Likelihood: mu (log link) 

Loss function: -(lgamma(y + sigma) - lgamma(sigma) - lgamma(y + 1) + sigma *  
     log(sigma) + y * f - (y + sigma) * log(exp(f) + sigma)) 
 

	 Negative Negative-Binomial Likelihood: sigma (log link) 

Loss function: -(lgamma(y + exp(f)) - lgamma(exp(f)) - lgamma(y + 1) + exp(f) *  
     f + y * log(mu) - (y + exp(f)) * log(mu + exp(f))) 
 
> par(mfrow = c(1,2))
> plot(model2, xlim = c(0, max(mstop(model2))))
> ## all.equal(coef(model2), coef(model3)) # same!
> 
> ### WARNING: Subsetting via model[mstopnew] changes the model directly!
> ### For the original fit one has to subset again: model[mstop]
> 
> 
> 
> 
> base::assign(".dptime", (proc.time() - get(".ptime", pos = "CheckExEnv")), pos = "CheckExEnv")
> base::cat("mboostLSS", base::get(".format_ptime", pos = 'CheckExEnv')(get(".dptime", pos = "CheckExEnv")), "\n", file=base::get(".ExTimings", pos = 'CheckExEnv'), append=TRUE, sep="\t")
> graphics::par(get("par.postscript", pos = 'CheckExEnv'))
> cleanEx()
> nameEx("methods")
> ### * methods
> 
> flush(stderr()); flush(stdout())
> 
> base::assign(".ptime", proc.time(), pos = "CheckExEnv")
> ### Name: methods
> ### Title: Methods for mboostLSS
> ### Aliases: coef.mboostLSS coef.glmboostLSS risk risk.mboostLSS
> ###   [.mboostLSS mstop.mboostLSS mstop.oobag mstop.cvriskLSS selected
> ###   selected.mboostLSS fitted.mboostLSS predict.mboostLSS predint PI
> ###   plot.glmboostLSS plot.gamboostLSS plot.predint update.mboostLSS
> ###   model.weights model.weights.default model.weights.mboostLSS
> ### Keywords: methods
> 
> ### ** Examples
> 
> 
> ### generate data
> set.seed(1907)
> x1 <- rnorm(1000)
> x2 <- rnorm(1000)
> x3 <- rnorm(1000)
> x4 <- rnorm(1000)
> x5 <- rnorm(1000)
> x6 <- rnorm(1000)
> mu    <- exp(1.5 + x1^2 +0.5 * x2 - 3 * sin(x3) -1 * x4)
> sigma <- exp(-0.2 * x4 +0.2 * x5 +0.4 * x6)
> y <- numeric(1000)
> for( i in 1:1000)
+     y[i] <- rnbinom(1, size = sigma[i], mu = mu[i])
> dat <- data.frame(x1, x2, x3, x4, x5, x6, y)
> 
> ### fit a model
> model <- gamboostLSS(y ~ ., families = NBinomialLSS(), data = dat,
+                      control = boost_control(mstop = 400))
> 
> ### extract coefficients
> coef(model)
$mu
$mu$`bbs(x1, df = dfbase)`
          1           2           3           4           5           6 
 3.58171139  2.47642513  1.38321567  0.35846954 -0.55844450 -1.37386804 
          7           8           9          10          11          12 
-2.06458712 -2.59383111 -2.94780872 -3.13830905 -3.18456719 -3.09471615 
         13          14          15          16          17          18 
-2.86320001 -2.46725579 -1.87824927 -1.08842591 -0.09273062  1.10805073 
         19          20          21          22          23          24 
 2.48864870  4.00437945  5.60292622  7.22757798  8.84769996 10.46670845 

$mu$`bbs(x2, df = dfbase)`
           1            2            3            4            5            6 
-0.587567018 -0.597235489 -0.606895359 -0.616493825 -0.625795262 -0.634226162 
           7            8            9           10           11           12 
-0.640764144 -0.643706523 -0.640665097 -0.629114205 -0.606465892 -0.565608617 
          13           14           15           16           17           18 
-0.499359388 -0.406250941 -0.289077229 -0.151094932 -0.001816165  0.145180788 
          19           20           21           22           23           24 
 0.286945776  0.419084241  0.545588456  0.669020116  0.789859912  0.910388836 

$mu$`bbs(x3, df = dfbase)`
          1           2           3           4           5           6 
 0.56795274  0.55780411  0.54748652  0.53585628  0.51985234  0.49117077 
          7           8           9          10          11          12 
 0.42717980  0.28842829  0.05046406 -0.25478976 -0.54504698 -0.75532084 
         13          14          15          16          17          18 
-0.86898074 -0.89962648 -0.87265488 -0.81495209 -0.74603751 -0.67649672 
         19          20          21          22          23          24 
-0.61055474 -0.54837543 -0.48890118 -0.43106752 -0.37389397 -0.31679225 

$mu$`bbs(x4, df = dfbase)`
           1            2            3            4            5            6 
 2.567451544  2.183750845  1.800221518  1.415979616  1.034193922  0.667283578 
           7            8            9           10           11           12 
 0.322037905  0.009307943 -0.257545411 -0.481058705 -0.669711734 -0.813301926 
          13           14           15           16           17           18 
-0.899364082 -0.932976652 -0.928286940 -0.899492000 -0.856040251 -0.804129859 
          19           20           21           22           23           24 
-0.747632885 -0.688917493 -0.629440065 -0.569818844 -0.510251318 -0.450694813 

attr(,"offset")
[1] 8.987845

$sigma
$sigma$`bbs(x1, df = dfbase)`
          1           2           3           4           5           6 
 0.89659893  0.78713824  0.67616360  0.55710969  0.42730638  0.29198962 
          7           8           9          10          11          12 
 0.16213560  0.05105498 -0.03122623 -0.07636368 -0.07847080 -0.03347975 
         13          14          15          16          17          18 
 0.05806291  0.17903227  0.30635650  0.42810619  0.53761725  0.62880999 
         19          20          21          22          23          24 
 0.69997365  0.75391415  0.79637610  0.83506324  0.87429112  0.91365873 

$sigma$`bbs(x2, df = dfbase)`
           1            2            3            4            5            6 
-0.563658099 -0.511757632 -0.459777813 -0.407331656 -0.354135638 -0.300469789 
           7            8            9           10           11           12 
-0.248309055 -0.199527201 -0.154491030 -0.108894039 -0.058401175 -0.002441743 
          13           14           15           16           17           18 
 0.056485633  0.113495345  0.164241662  0.204929795  0.235290786  0.264020513 
          19           20           21           22           23           24 
 0.296512365  0.333895128  0.373456407  0.413559904  0.453779441  0.494022639 

$sigma$`bbs(x3, df = dfbase)`
          1           2           3           4           5           6 
-0.06993609  0.21499858  0.50028302  0.78648040  1.06468531  1.31096130 
          7           8           9          10          11          12 
 1.49064677  1.57871832  1.56759726  1.44135824  1.19071516  0.83344537 
         13          14          15          16          17          18 
 0.42510438  0.03477713 -0.30056403 -0.55740737 -0.72441644 -0.78900239 
         19          20          21          22          23          24 
-0.75566343 -0.65077256 -0.49956583 -0.32729936 -0.14808084  0.03192021 

$sigma$`bbs(x4, df = dfbase)`
          1           2           3           4           5           6 
 0.96287395  0.92067646  0.87872609  0.83856810  0.80135245  0.76642932 
          7           8           9          10          11          12 
 0.73502975  0.69991232  0.65251688  0.58964226  0.51238783  0.41489277 
         13          14          15          16          17          18 
 0.29149880  0.14358469 -0.01622096 -0.18308842 -0.36174266 -0.55165256 
         19          20          21          22          23          24 
-0.75216843 -0.96121405 -1.17697566 -1.39582787 -1.61463881 -1.83317154 

$sigma$`bbs(x5, df = dfbase)`
          1           2           3           4           5           6 
-0.35133403 -0.31818178 -0.28487218 -0.25048316 -0.21414472 -0.17551639 
          7           8           9          10          11          12 
-0.13478066 -0.09043638 -0.04036516  0.01140995  0.05490236  0.08804387 
         13          14          15          16          17          18 
 0.11539467  0.13861908  0.15950497  0.17917571  0.19811973  0.21841061 
         19          20          21          22          23          24 
 0.23971872  0.26186474  0.28466756  0.30781904  0.33074669  0.35356977 

$sigma$`bbs(x6, df = dfbase)`
            1             2             3             4             5 
-0.2844651880 -0.2186158355 -0.1534117880 -0.0928846917 -0.0448736951 
            6             7             8             9            10 
-0.0144611066 -0.0007836747  0.0043527943  0.0116311707  0.0272086244 
           11            12            13            14            15 
 0.0517831869  0.0848199173  0.1248441166  0.1671483807  0.2026641167 
           16            17            18            19            20 
 0.2336020503  0.2661041115  0.3023380856  0.3417998069  0.3836024077 
           21            22            23            24 
 0.4268453691  0.4711745653  0.5160781652  0.5610761947 

attr(,"offset")
[1] -2.427222

> 
> ### only for distribution parameter mu
> coef(model, parameter = "mu")
$`bbs(x1, df = dfbase)`
          1           2           3           4           5           6 
 3.58171139  2.47642513  1.38321567  0.35846954 -0.55844450 -1.37386804 
          7           8           9          10          11          12 
-2.06458712 -2.59383111 -2.94780872 -3.13830905 -3.18456719 -3.09471615 
         13          14          15          16          17          18 
-2.86320001 -2.46725579 -1.87824927 -1.08842591 -0.09273062  1.10805073 
         19          20          21          22          23          24 
 2.48864870  4.00437945  5.60292622  7.22757798  8.84769996 10.46670845 

$`bbs(x2, df = dfbase)`
           1            2            3            4            5            6 
-0.587567018 -0.597235489 -0.606895359 -0.616493825 -0.625795262 -0.634226162 
           7            8            9           10           11           12 
-0.640764144 -0.643706523 -0.640665097 -0.629114205 -0.606465892 -0.565608617 
          13           14           15           16           17           18 
-0.499359388 -0.406250941 -0.289077229 -0.151094932 -0.001816165  0.145180788 
          19           20           21           22           23           24 
 0.286945776  0.419084241  0.545588456  0.669020116  0.789859912  0.910388836 

$`bbs(x3, df = dfbase)`
          1           2           3           4           5           6 
 0.56795274  0.55780411  0.54748652  0.53585628  0.51985234  0.49117077 
          7           8           9          10          11          12 
 0.42717980  0.28842829  0.05046406 -0.25478976 -0.54504698 -0.75532084 
         13          14          15          16          17          18 
-0.86898074 -0.89962648 -0.87265488 -0.81495209 -0.74603751 -0.67649672 
         19          20          21          22          23          24 
-0.61055474 -0.54837543 -0.48890118 -0.43106752 -0.37389397 -0.31679225 

$`bbs(x4, df = dfbase)`
           1            2            3            4            5            6 
 2.567451544  2.183750845  1.800221518  1.415979616  1.034193922  0.667283578 
           7            8            9           10           11           12 
 0.322037905  0.009307943 -0.257545411 -0.481058705 -0.669711734 -0.813301926 
          13           14           15           16           17           18 
-0.899364082 -0.932976652 -0.928286940 -0.899492000 -0.856040251 -0.804129859 
          19           20           21           22           23           24 
-0.747632885 -0.688917493 -0.629440065 -0.569818844 -0.510251318 -0.450694813 

attr(,"offset")
[1] 8.987845
> 
> ### only for covariate x1
> coef(model, which = "x1")
$mu
$mu$`bbs(x1, df = dfbase)`
          1           2           3           4           5           6 
 3.58171139  2.47642513  1.38321567  0.35846954 -0.55844450 -1.37386804 
          7           8           9          10          11          12 
-2.06458712 -2.59383111 -2.94780872 -3.13830905 -3.18456719 -3.09471615 
         13          14          15          16          17          18 
-2.86320001 -2.46725579 -1.87824927 -1.08842591 -0.09273062  1.10805073 
         19          20          21          22          23          24 
 2.48864870  4.00437945  5.60292622  7.22757798  8.84769996 10.46670845 

attr(,"offset")
[1] 8.987845

$sigma
$sigma$`bbs(x1, df = dfbase)`
          1           2           3           4           5           6 
 0.89659893  0.78713824  0.67616360  0.55710969  0.42730638  0.29198962 
          7           8           9          10          11          12 
 0.16213560  0.05105498 -0.03122623 -0.07636368 -0.07847080 -0.03347975 
         13          14          15          16          17          18 
 0.05806291  0.17903227  0.30635650  0.42810619  0.53761725  0.62880999 
         19          20          21          22          23          24 
 0.69997365  0.75391415  0.79637610  0.83506324  0.87429112  0.91365873 

attr(,"offset")
[1] -2.427222

> 
> 
> ### plot complete model
> par(mfrow = c(4, 3))
> plot(model)
> ### plot first parameter only
> par(mfrow = c(2, 3))
> plot(model, parameter = "mu")
> ### now plot only effect of x3 of both parameters
> par(mfrow = c(1, 2))
> plot(model, which = "x3")
> ### first component second parameter (sigma)
> par(mfrow = c(1, 1))
> plot(model, which = 1, parameter = 2)
> 
> ### plot marginal prediction interval
> pi <- predint(model, pi = 0.9, which = "x1")
> pi <- predint(model, pi = c(0.8, 0.9), which = "x1")
> plot(pi, log = "y")  # warning as some y values are below 0
Warning in xy.coords(x, y, xlabel, ylabel, log) :
  229 y values <= 0 omitted from logarithmic plot
> ## here it would be better to plot x1 against
> ## sqrt(y) and sqrt(PI)
> 
> ### subset model for mstop = 300 (one-dimensional)
> model[300]

	 LSS Models fitted via Model-based Boosting

Call:
gamboostLSS(formula = y ~ ., data = dat, families = NBinomialLSS(),     control = boost_control(mstop = 400))

Number of boosting iterations: mstop = 300 300 
Step size:  0.1 

Families:

	 Negative Negative-Binomial Likelihood: mu (log link) 

Loss function: -(lgamma(y + sigma) - lgamma(sigma) - lgamma(y + 1) + sigma *  
     log(sigma) + y * f - (y + sigma) * log(exp(f) + sigma)) 
 

	 Negative Negative-Binomial Likelihood: sigma (log link) 

Loss function: -(lgamma(y + exp(f)) - lgamma(exp(f)) - lgamma(y + 1) + exp(f) *  
     f + y * log(mu) - (y + exp(f)) * log(mu + exp(f))) 
 
> 
> # WARNING: Subsetting via model[mstopnew] changes the model directly!
> # For the original fit one has to subset again: model[mstop]
> 
> par(mfrow = c(2, 2))
> plot(risk(model, parameter = "mu")[[1]])
> plot(risk(model, parameter = "sigma")[[1]])
> ### get back to orignal fit
> model[400]

	 LSS Models fitted via Model-based Boosting

Call:
gamboostLSS(formula = y ~ ., data = dat, families = NBinomialLSS(),     control = boost_control(mstop = 400))

Number of boosting iterations: mstop = 400 400 
Step size:  0.1 

Families:

	 Negative Negative-Binomial Likelihood: mu (log link) 

Loss function: -(lgamma(y + sigma) - lgamma(sigma) - lgamma(y + 1) + sigma *  
     log(sigma) + y * f - (y + sigma) * log(exp(f) + sigma)) 
 

	 Negative Negative-Binomial Likelihood: sigma (log link) 

Loss function: -(lgamma(y + exp(f)) - lgamma(exp(f)) - lgamma(y + 1) + exp(f) *  
     f + y * log(mu) - (y + exp(f)) * log(mu + exp(f))) 
 
> plot(risk(model, parameter = "mu")[[1]])
> plot(risk(model, parameter = "sigma")[[1]])
> 
> ### use different mstop values for the components
> model[c(100, 200)]

	 LSS Models fitted via Model-based Boosting

Call:
gamboostLSS(formula = y ~ ., data = dat, families = NBinomialLSS(),     control = boost_control(mstop = 400))

Number of boosting iterations: mstop = 100 200 
Step size:  0.1 

Families:

	 Negative Negative-Binomial Likelihood: mu (log link) 

Loss function: -(lgamma(y + sigma) - lgamma(sigma) - lgamma(y + 1) + sigma *  
     log(sigma) + y * f - (y + sigma) * log(exp(f) + sigma)) 
 

	 Negative Negative-Binomial Likelihood: sigma (log link) 

Loss function: -(lgamma(y + exp(f)) - lgamma(exp(f)) - lgamma(y + 1) + exp(f) *  
     f + y * log(mu) - (y + exp(f)) * log(mu + exp(f))) 
 
> ## same as
>   model[c(mu = 100, sigma = 200)]

	 LSS Models fitted via Model-based Boosting

Call:
gamboostLSS(formula = y ~ ., data = dat, families = NBinomialLSS(),     control = boost_control(mstop = 400))

Number of boosting iterations: mstop = 100 200 
Step size:  0.1 

Families:

	 Negative Negative-Binomial Likelihood: mu (log link) 

Loss function: -(lgamma(y + sigma) - lgamma(sigma) - lgamma(y + 1) + sigma *  
     log(sigma) + y * f - (y + sigma) * log(exp(f) + sigma)) 
 

	 Negative Negative-Binomial Likelihood: sigma (log link) 

Loss function: -(lgamma(y + exp(f)) - lgamma(exp(f)) - lgamma(y + 1) + exp(f) *  
     f + y * log(mu) - (y + exp(f)) * log(mu + exp(f))) 
 
> ## or
>   model[list(mu = 100, sigma = 200)]

	 LSS Models fitted via Model-based Boosting

Call:
gamboostLSS(formula = y ~ ., data = dat, families = NBinomialLSS(),     control = boost_control(mstop = 400))

Number of boosting iterations: mstop = 100 200 
Step size:  0.1 

Families:

	 Negative Negative-Binomial Likelihood: mu (log link) 

Loss function: -(lgamma(y + sigma) - lgamma(sigma) - lgamma(y + 1) + sigma *  
     log(sigma) + y * f - (y + sigma) * log(exp(f) + sigma)) 
 

	 Negative Negative-Binomial Likelihood: sigma (log link) 

Loss function: -(lgamma(y + exp(f)) - lgamma(exp(f)) - lgamma(y + 1) + exp(f) *  
     f + y * log(mu) - (y + exp(f)) * log(mu + exp(f))) 
 
> ## or
>   model[list(100, 200)]

	 LSS Models fitted via Model-based Boosting

Call:
gamboostLSS(formula = y ~ ., data = dat, families = NBinomialLSS(),     control = boost_control(mstop = 400))

Number of boosting iterations: mstop = 100 200 
Step size:  0.1 

Families:

	 Negative Negative-Binomial Likelihood: mu (log link) 

Loss function: -(lgamma(y + sigma) - lgamma(sigma) - lgamma(y + 1) + sigma *  
     log(sigma) + y * f - (y + sigma) * log(exp(f) + sigma)) 
 

	 Negative Negative-Binomial Likelihood: sigma (log link) 

Loss function: -(lgamma(y + exp(f)) - lgamma(exp(f)) - lgamma(y + 1) + exp(f) *  
     f + y * log(mu) - (y + exp(f)) * log(mu + exp(f))) 
 
> 
> plot(risk(model, parameter = "mu")[[1]])
> plot(risk(model, parameter = "sigma")[[1]])
> 
> 
> 
> 
> base::assign(".dptime", (proc.time() - get(".ptime", pos = "CheckExEnv")), pos = "CheckExEnv")
> base::cat("methods", base::get(".format_ptime", pos = 'CheckExEnv')(get(".dptime", pos = "CheckExEnv")), "\n", file=base::get(".ExTimings", pos = 'CheckExEnv'), append=TRUE, sep="\t")
> graphics::par(get("par.postscript", pos = 'CheckExEnv'))
> ### * <FOOTER>
> ###
> options(digits = 7L)
> base::cat("Time elapsed: ", proc.time() - base::get("ptime", pos = 'CheckExEnv'),"\n")
Time elapsed:  70.828 0.408 71.836 0 0 
> grDevices::dev.off()
null device 
          1 
> ###
> ### Local variables: ***
> ### mode: outline-minor ***
> ### outline-regexp: "\\(> \\)?### [*]+" ***
> ### End: ***
> quit('no')
