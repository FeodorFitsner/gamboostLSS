
R version 2.11.1 (2010-05-31)
Copyright (C) 2010 The R Foundation for Statistical Computing
ISBN 3-900051-07-0

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> ###
> # check families
> 
> require("gamboostLSS")
Loading required package: gamboostLSS
Loading required package: mboost
Loading required package: survival
Loading required package: splines
> require("gamlss")
Loading required package: gamlss
Loading required package: gamlss.dist
Loading required package: gamlss.data
 **********   GAMLSS Version 4.0-0 ********** 
For more on GAMLSS look at http://www.gamlss.com/ 
Type gamlssNews() to see new features/changes/bug fixes.

Attaching package: 'gamlss'

The following object(s) are masked from 'package:survival':

    ridge

> 
> 
> ### check families with only one offset specified (other to choose via optim)
> set.seed(1907)
> n <- 5000
> x1  <- runif(n)
> x2 <- runif(n)
> mu <- 2 -1*x1 - 3*x2
> sigma <- exp(-1*x1 + 3*x2)
> df <- exp(1 + 3*x1 + 1*x2)
> y <- rTF(n = n, mu = mu, sigma = sigma, nu = df)
> data <- data.frame(y = y, x1 = x1, x2 = x2)
> rm("y", "x1", "x2")
> 
> model <- glmboostLSS(y ~ x1 + x2, families = StudentTLSS(mu = 0.5),
+                      data = data,
+                      control = boost_control(mstop = 10))
> coef(model)
$mu
(Intercept)          x2 
  0.1743629  -0.3520006 
attr(,"offset")
[1] 0.5

$sigma
(Intercept)          x1          x2 
 -0.8953163  -0.7540091   2.5726033 
attr(,"offset")
[1] 1.151955

$df
(Intercept)          x2 
 0.10870783 -0.02897715 
attr(,"offset")
[1] 0.8369583

> 
> model <- glmboostLSS(y ~ x1 + x2, families = StudentTLSS(sigma = 1),
+                      data = data,
+                      control = boost_control(mstop = 10))
> coef(model)
$mu
(Intercept)          x2 
  0.2684299  -0.5419014 
attr(,"offset")
[1] 0.5774545

$sigma
(Intercept)          x2 
  -1.480476    2.988759 
attr(,"offset")
[1] 0

$df
(Intercept)          x1          x2 
  0.1661285   0.1057652  -0.4217916 
attr(,"offset")
[1] -0.1776425

> 
> model <- glmboostLSS(y ~ x1 + x2, families = StudentTLSS(df = 4),
+                      data = data,
+                      control = boost_control(mstop = 10))
> coef(model)
$mu
(Intercept)          x2 
  0.1537689  -0.3104259 
attr(,"offset")
[1] 0.5774545

$sigma
(Intercept)          x1          x2 
 -0.8640059  -0.7435193   2.4987496 
attr(,"offset")
[1] 1.152757

$df
(Intercept)          x1          x2 
 0.05557042  0.01616506 -0.05414564 
attr(,"offset")
[1] 1.386294

> 
> model <- glmboostLSS(y ~ x1 + x2, families = StudentTLSS(mu = 0.5, df = 1),
+                      data = data,
+                      control = boost_control(mstop = 10))
> coef(model)
$mu
(Intercept)          x2 
  0.3228816  -0.6518276 
attr(,"offset")
[1] 0.5

$sigma
(Intercept)          x2 
  -2.419432    4.884306 
attr(,"offset")
[1] 0.548112

$df
(Intercept)          x2 
 0.08637356  0.04414274 
attr(,"offset")
[1] 0

> 
> ### multivariate minimum for offset
> loss <- function(df, sigma,y, f){
+     -1 * (lgamma((df+1)/2) - log(sigma) - lgamma(1/2) - lgamma(df/2) - 0.5 *
+           log(df) - (df+1)/2 * log(1 + (y-f)^2 / (df * sigma^2)))
+ }
> riski <- function(x, y, w = rep(1, length(y))){
+     f <- x[[1]]
+     df <- exp(x[[2]])
+     sigma <- exp(x[[3]])
+     sum(w * loss(y = y, f = f, df = df, sigma = sigma))
+ }
> 
> res <- optim(fn = riski, par = c(0, 1, 1), y = data$y, w = rep(1, length(data$y)))$par
> model <- glmboostLSS(y ~ x1 + x2, families = StudentTLSS(mu = res[1], sigma =
+                                   exp(res[2]), df = exp(res[3])),
+                      data = data,
+                      control = boost_control(mstop = 10))
> model[100]

	 Generalized Linear Models Fitted via Gradient Boosting

Call:
glmboost.formula(formula = formula[[names(families)[[j]]]], data = data,     weights = w, control = control, family = families[[j]])


	 Student's t-distribution: mu (id link) 

Loss function: { 
     -1 * (lgamma((df + 1)/2) - log(sigma) - lgamma(1/2) - lgamma(df/2) -  
         0.5 * log(df) - (df + 1)/2 * log(1 + (y - f)^2/(df *  
         sigma^2))) 
 } 
 

Number of boosting iterations: mstop = 100 
Step size:  0.1 
Offset:  0.5228725 

Coefficients: 
(Intercept)          x1          x2 
   1.507443   -1.272131   -1.840329 
attr(,"offset")
[1] 0.5228725


	 Generalized Linear Models Fitted via Gradient Boosting

Call:
glmboost.formula(formula = formula[[names(families)[[j]]]], data = data,     weights = w, control = control, family = families[[j]])


	 Student's t-distribution: sigma (log link) 

Loss function: { 
     -1 * (lgamma((df + 1)/2) - f - lgamma(1/2) - lgamma(df/2) -  
         0.5 * log(df) - (df + 1)/2 * log(1 + (y - mu)^2/(df *  
         exp(2 * f)))) 
 } 
 

Number of boosting iterations: mstop = 100 
Step size:  0.1 
Offset:  0.3968482 

Coefficients: 
(Intercept)          x1          x2 
  -4.857660   -1.229536    9.336231 
attr(,"offset")
[1] 0.3968482


	 Generalized Linear Models Fitted via Gradient Boosting

Call:
glmboost.formula(formula = formula[[names(families)[[j]]]], data = data,     weights = w, control = control, family = families[[j]])


	 Student's t-distribution: df (log link) 

Loss function: { 
     -1 * (lgamma((exp(f) + 1)/2) - log(sigma) - lgamma(1/2) -  
         lgamma(exp(f)/2) - 0.5 * f - (exp(f) + 1)/2 * log(1 +  
         (y - mu)^2/(exp(f) * sigma^2))) 
 } 
 

Number of boosting iterations: mstop = 100 
Step size:  0.1 
Offset:  0.7357846 

Coefficients: 
(Intercept)          x1          x2 
 -2.4181928   0.1476135   3.6072253 
attr(,"offset")
[1] 0.7357846

> coef(model)
$mu
(Intercept)          x1          x2 
   1.507443   -1.272131   -1.840329 
attr(,"offset")
[1] 0.5228725

$sigma
(Intercept)          x1          x2 
  -4.857660   -1.229536    9.336231 
attr(,"offset")
[1] 0.3968482

$df
(Intercept)          x1          x2 
 -2.4181928   0.1476135   3.6072253 
attr(,"offset")
[1] 0.7357846

> 
> ### check survival families
> 
> # LogNormalLSS()
> x1 <- runif(1000)
> x2 <- runif(1000)
> x3 <- runif(1000)
> w <- rnorm(1000)
> 
> time <-  exp(3 + 1*x1 +2*x2  + exp(0.2 * x3) * w)
> status <- rep(1, 1000)
> (m1 <- survreg(Surv(time, status) ~ x1 + x2 + x3, dist="lognormal"))
Call:
survreg(formula = Surv(time, status) ~ x1 + x2 + x3, dist = "lognormal")

Coefficients:
(Intercept)          x1          x2          x3 
 2.88588933  1.15548098  2.03642866  0.09869623 

Scale= 1.135837 

Loglik(model)= -6051   Loglik(intercept only)= -6199.6
	Chisq= 297.2 on 3 degrees of freedom, p= 0 
n= 1000 
> model <- glmboostLSS(Surv(time, status) ~ x1 + x2 + x3, families = LogNormalLSS(),
+                      control = boost_control(trace = TRUE))
[   1] ...................................... -- risk: 1552.695 
[  41] ...................................... -- risk: 1543.948 
[  81] ..................
Final risk: 1543.569 
> stopifnot(sum(abs(coef(model, off2int = TRUE)[[1]] - c(3, 1, 2, 0)))
+           < sum(abs(coef(m1) - c(3, 1, 2, 0))))
> stopifnot(sum(abs(coef(model, off2int = TRUE)[[2]] - c(0, 0, 0, 0.2))) < 0.25)
> 
> # LogLogLSS()
> etamu <- 3 + 1*x1 +2*x2
> etasi <- exp(rep(0.2, 1000))
> for (i in 1:1000)
+     time[i] <- exp(rlogis(1, location = etamu[i], scale = etasi[i]))
> status <- rep(1, 1000)
> (m1 <- survreg(Surv(time, status) ~ x1 + x2 + x3, dist="loglogistic"))
Call:
survreg(formula = Surv(time, status) ~ x1 + x2 + x3, dist = "loglogistic")

Coefficients:
(Intercept)          x1          x2          x3 
  3.2109423   0.6543336   2.0799870  -0.2505811 

Scale= 1.257854 

Loglik(model)= -6681.6   Loglik(intercept only)= -6721.9
	Chisq= 80.57 on 3 degrees of freedom, p= 0 
n= 1000 
> model <- glmboostLSS(Surv(time, status) ~ x1 + x2 + x3, families = LogLogLSS(),
+                      control = boost_control(trace = TRUE))
[   1] ...................................... -- risk: 2246.758 
[  41] ...................................... -- risk: 2240.168 
[  81] ..................
Final risk: 2238.548 
> model[350]
[ 101] ...................................... -- risk: 2236.777 
[ 141] ...................................... -- risk: 2235.907 
[ 181] ...................................... -- risk: 2235.422 
[ 221] ...................................... -- risk: 2235.153 
[ 261] ...................................... -- risk: 2235.003 
[ 301] ...................................... -- risk: 2234.92 
[ 341] ........
Final risk: 2234.906 

	 Generalized Linear Models Fitted via Gradient Boosting

Call:
glmboost.formula(formula = formula[[names(families)[[j]]]], data = data,     weights = w, control = control, family = families[[j]])


	 Log-Logistic AFT Model: mu (id link) 

Loss function: { 
     logfw <- function(pred) dlogis(pred, log = TRUE) 
     logSw <- function(pred) plogis(pred, lower.tail = FALSE,  
         log.p = TRUE) 
     eta <- (log(y[, 1]) - f)/sigma 
     -y[, 2] * (logfw(eta) - log(sigma)) - (1 - y[, 2]) * logSw(eta) 
 } 
 

Number of boosting iterations: mstop = 350 
Step size:  0.1 
Offset:  4.428274 

Coefficients: 
(Intercept)          x1          x2          x3 
 -1.1733139   0.6072775   1.9909091  -0.2065531 
attr(,"offset")
[1] 4.428274


	 Generalized Linear Models Fitted via Gradient Boosting

Call:
glmboost.formula(formula = formula[[names(families)[[j]]]], data = data,     weights = w, control = control, family = families[[j]])


	 Log-Logistic AFT Model: sigma (log link) 

Loss function: { 
     logfw <- function(pred) dlogis(pred, log = TRUE) 
     logSw <- function(pred) pnorm(pred, lower.tail = FALSE, log.p = TRUE) 
     eta <- (log(y[, 1]) - mu)/exp(f) 
     -y[, 2] * (logfw(eta) - f) - (1 - y[, 2]) * logSw(eta) 
 } 
 

Number of boosting iterations: mstop = 350 
Step size:  0.1 
Offset:  0.2709814 

Coefficients: 
 (Intercept)           x1           x2           x3 
-0.045221333 -0.088175343  0.007858947  0.086315716 
attr(,"offset")
[1] 0.2709814

> stopifnot(sum(abs(coef(model, off2int = TRUE, which ="")[[1]] - c(3, 1, 2, 0)))
+           < sum(abs(coef(m1) - c(3, 1, 2, 0))))
> stopifnot(sum(abs(coef(model, off2int = TRUE)[[2]] - c(0.2, 0, 0, 0))) < 0.25)
> 
> # WeibullLSS()
> etamu <- 3 + 1*x1 +2*x2
> etasi <- exp(rep(0.2, 1000))
> status <- rep(1, 1000)
> time <- rep(NA, 1000)
> for (i in 1:1000)
+     time[i] <- rweibull(1, shape = exp(- 0.2), scale = exp(etamu[i]))
> (m1 <- survreg(Surv(time, status) ~ x1 + x2 + x3, dist="weibull"))
Call:
survreg(formula = Surv(time, status) ~ x1 + x2 + x3, dist = "weibull")

Coefficients:
 (Intercept)           x1           x2           x3 
 3.047471670  1.008282745  1.934326789 -0.007107055 

Scale= 1.230652 

Loglik(model)= -5567.4   Loglik(intercept only)= -5684.9
	Chisq= 235.11 on 3 degrees of freedom, p= 0 
n= 1000 
> model <- glmboostLSS(Surv(time, status) ~ x1 + x2 + x3,
+                      families = WeibullLSS(),
+                      control = boost_control(trace = TRUE))
[   1] ...................................... -- risk: 2134.384 
[  41] ...................................... -- risk: 1904.389 
[  81] ..................
Final risk: 1858.757 
> model[300]
[ 101] ...................................... -- risk: 1804.158 
[ 141] ...................................... -- risk: 1782.137 
[ 181] ...................................... -- risk: 1775.546 
[ 221] ...................................... -- risk: 1773.984 
[ 261] ......................................
Final risk: 1773.656 

	 Generalized Linear Models Fitted via Gradient Boosting

Call:
glmboost.formula(formula = formula[[names(families)[[j]]]], data = data,     weights = w, control = control, family = families[[j]])


	 Weibull AFT Model: mu (id link) 

Loss function: { 
     logfw <- function(pred) pred - exp(pred) 
     logSw <- function(pred) -exp(pred) 
     eta <- (log(y[, 1]) - f)/sigma 
     -y[, 2] * (logfw(eta) - log(sigma)) - (1 - y[, 2]) * logSw(eta) 
 } 
 

Number of boosting iterations: mstop = 300 
Step size:  0.1 
Offset:  1.569460 

Coefficients: 
(Intercept)          x1          x2 
   1.435110    1.012545    1.992845 
attr(,"offset")
[1] 1.569460


	 Generalized Linear Models Fitted via Gradient Boosting

Call:
glmboost.formula(formula = formula[[names(families)[[j]]]], data = data,     weights = w, control = control, family = families[[j]])


	 Weibull AFT Model: sigma (log link) 

Loss function: { 
     logfw <- function(pred) pred - exp(pred) 
     logSw <- function(pred) -exp(pred) 
     eta <- (log(y[, 1]) - mu)/exp(f) 
     -y[, 2] * (logfw(eta) - f) - (1 - y[, 2]) * logSw(eta) 
 } 
 

Number of boosting iterations: mstop = 300 
Step size:  0.1 
Offset:  0.313215 

Coefficients: 
(Intercept)          x1          x2          x3 
-0.03347056 -0.05420302 -0.13905380  0.04472299 
attr(,"offset")
[1] 0.313215

> stopifnot(sum(abs(coef(model, off2int = TRUE, which ="")[[1]] - c(3, 1, 2, 0)))
+           < sum(abs(coef(m1) - c(3, 1, 2, 0))))
> stopifnot(sum(abs(coef(model, off2int = TRUE)[[2]] - c(0.2, 0, 0, 0))) < 0.4)
> 
> ### Check that "families"-object contains a response function
> NBinomialMu2 <- function(...){
+     RET <- NBinomialMu(...)
+     RET@response <- function(f) NA
+     RET
+ }
> 
> NBinomialSigma2 <- function(...){
+     RET <- NBinomialSigma(...)
+     RET@response <- function(f) NA
+     RET
+ }
> 
> NBinomialLSS2 <- function(mu = NULL, sigma = NULL){
+     if ((!is.null(sigma) && sigma <= 0) || (!is.null(mu) && mu <= 0))
+         stop(sQuote("sigma"), " and ", sQuote("mu"),
+              " must be greater than zero")
+     RET <- makeFamilies(mu = NBinomialMu2(mu = mu, sigma = sigma),
+                         sigma = NBinomialSigma2(mu = mu, sigma = sigma))
+     return(RET)
+ }
> 
> try(NBinomialLSS2())
Error in makeFamilies(mu = NBinomialMu2(mu = mu, sigma = sigma), sigma = NBinomialSigma2(mu = mu,  : 
  response function not specified in families for:
	mu, sigma
> 
> #detach("package:gamboostLSS", unload = TRUE)
> 
